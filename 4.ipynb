{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1de44d48",
   "metadata": {},
   "source": [
    "Anomaly detection algorithms can be broadly categorized into the following main types:\n",
    "\n",
    "Statistical Methods:\n",
    "\n",
    "Univariate Methods: These methods focus on analyzing individual features independently. Common techniques include Gaussian distribution modeling, z-score, and percentile-based approaches.\n",
    "Multivariate Methods: These methods consider correlations between multiple features simultaneously. Techniques such as principal component analysis (PCA) and multivariate Gaussian distribution modeling fall into this category.\n",
    "Machine Learning-Based Methods:\n",
    "\n",
    "Supervised Learning: In supervised anomaly detection, the algorithm is trained on labeled data, where both normal and anomalous instances are provided. Popular supervised techniques include Support Vector Machines (SVM), Random Forests, and Neural Networks.\n",
    "Semi-Supervised Learning: Semi-supervised methods train on a dataset that mostly consists of normal instances, with a few labeled anomalies. One-class SVM and Autoencoders are common semi-supervised techniques.\n",
    "Unsupervised Learning: Unsupervised anomaly detection algorithms do not require labeled data. They identify anomalies based on deviations from normal patterns in the data. Clustering-based methods, density-based methods like DBSCAN, and isolation forest are examples of unsupervised approaches.\n",
    "Proximity-Based Methods:\n",
    "\n",
    "These methods measure the similarity or dissimilarity between data points. Anomalies are identified as instances that are significantly different from their neighbors. Nearest neighbor algorithms, such as k-nearest neighbors (KNN), and density-based methods, like LOF (Local Outlier Factor), fall into this category.\n",
    "Information Theory-Based Methods:\n",
    "\n",
    "These methods utilize concepts from information theory to detect anomalies by measuring unexpectedness or entropy in the data. For instance, entropy-based techniques quantify the unpredictability of data patterns.\n",
    "Deep Learning-Based Methods:\n",
    "\n",
    "Deep learning techniques, particularly autoencoders, have shown promise in anomaly detection tasks. Autoencoders are neural networks trained to reconstruct input data, and anomalies are identified based on reconstruction errors.\n",
    "Time Series-Specific Methods:\n",
    "\n",
    "Time series data often require specialized techniques for anomaly detection. Methods such as Seasonal Decomposition of Time Series (STL), Exponential Smoothing, and Recurrent Neural Networks (RNNs) with Long Short-Term Memory (LSTM) cells are commonly used for detecting anomalies in time series data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
